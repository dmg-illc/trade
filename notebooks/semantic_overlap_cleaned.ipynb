{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from os.path import join\n",
    "import pickle\n",
    "from scipy.stats import pearsonr, ttest_ind, spearmanr\n",
    "\n",
    "OUTPUT_PATH = '/Users/anna/Documents/Code/Ads/data/outputs'\n",
    "sys.path.append(OUTPUT_PATH) \n",
    "from bert_utils import SentenceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textual overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(OUTPUT_PATH,'test_right.json'), 'r') as my_right_file:\n",
    "    right_data=my_right_file.read()\n",
    "right_dict = json.loads(right_data)\n",
    "\n",
    "\n",
    "with open(join(OUTPUT_PATH,'test_wrong.json'), 'r') as my_wrong_file:\n",
    "    wrong_data=my_wrong_file.read()\n",
    "wrong_dict = json.loads(wrong_data)\n",
    "ocr_df = pd.read_csv(join(OUTPUT_PATH, 'text_sim.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the test set: 12805\n",
      "Test set samples with OCR-extracred text: 12304\n",
      "(12304, 5)\n",
      "Number of null texts: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>all_answers</th>\n",
       "      <th>wrong_answers</th>\n",
       "      <th>right_answers_update</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174225.png</td>\n",
       "      <td>['I should buy Versace Becuase its bright', 'I...</td>\n",
       "      <td>['I should buy Versace Becuase its bright'\\n '...</td>\n",
       "      <td>['I should watch the amount I drink, because t...</td>\n",
       "      <td>BEER BEE AGE bac OUT DEPEN IM iVer disease esi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88925.jpg</td>\n",
       "      <td>[\"I should buy from the Farmer's Market Becaus...</td>\n",
       "      <td>[\"I should buy from the Farmer's Market Becaus...</td>\n",
       "      <td>['I should have this car because it is nice an...</td>\n",
       "      <td>L INC OL N CONTINENTA L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173505.png</td>\n",
       "      <td>['I should use mySIM Plans because they are mo...</td>\n",
       "      <td>['I should use Boost Mobile  Because it is a c...</td>\n",
       "      <td>['I should use mySIM Plans because they are mo...</td>\n",
       "      <td>mySIM Plans and Phone Deal:s Enjoy even greate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173522.png</td>\n",
       "      <td>['I should go grocery shopping at Meijer Becau...</td>\n",
       "      <td>['I should go grocery shopping at Meijer Becau...</td>\n",
       "      <td>['I should buy Dior cosmetics because they wil...</td>\n",
       "      <td>ior DIORSHOW ICONIC OVERCURL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92004.jpg</td>\n",
       "      <td>[\"I should buy Hershey's kisses Because they'r...</td>\n",
       "      <td>[\"I should buy Hershey's kisses Because they'r...</td>\n",
       "      <td>['I should buy this Manavox tv Because I like ...</td>\n",
       "      <td>NEW! COMPUTER COLOR FROM MAGNAVOX TOUCH TUNE E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_file                                        all_answers  \\\n",
       "0  174225.png  ['I should buy Versace Becuase its bright', 'I...   \n",
       "1   88925.jpg  [\"I should buy from the Farmer's Market Becaus...   \n",
       "2  173505.png  ['I should use mySIM Plans because they are mo...   \n",
       "3  173522.png  ['I should go grocery shopping at Meijer Becau...   \n",
       "4   92004.jpg  [\"I should buy Hershey's kisses Because they'r...   \n",
       "\n",
       "                                       wrong_answers  \\\n",
       "0  ['I should buy Versace Becuase its bright'\\n '...   \n",
       "1  [\"I should buy from the Farmer's Market Becaus...   \n",
       "2  ['I should use Boost Mobile  Because it is a c...   \n",
       "3  ['I should go grocery shopping at Meijer Becau...   \n",
       "4  [\"I should buy Hershey's kisses Because they'r...   \n",
       "\n",
       "                                right_answers_update  \\\n",
       "0  ['I should watch the amount I drink, because t...   \n",
       "1  ['I should have this car because it is nice an...   \n",
       "2  ['I should use mySIM Plans because they are mo...   \n",
       "3  ['I should buy Dior cosmetics because they wil...   \n",
       "4  ['I should buy this Manavox tv Because I like ...   \n",
       "\n",
       "                                                text  \n",
       "0  BEER BEE AGE bac OUT DEPEN IM iVer disease esi...  \n",
       "1                           L INC OL N CONTINENTA L   \n",
       "2  mySIM Plans and Phone Deal:s Enjoy even greate...  \n",
       "3                      ior DIORSHOW ICONIC OVERCURL   \n",
       "4  NEW! COMPUTER COLOR FROM MAGNAVOX TOUCH TUNE E...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Length of the test set:', len(right_dict))\n",
    "print('Test set samples with OCR-extracred text:', ocr_df.shape[0])\n",
    "print(ocr_df.shape)\n",
    "print('Number of null texts:', ocr_df.text.isnull().sum())\n",
    "ocr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text, lemmatizer=lemmatizer, tokenizer=tokenizer, stopwords=stop_words):\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemma_text = [lemmatizer.lemmatize(t.lower()) for t in tokens if t not in stop_words]\n",
    "\n",
    "    return lemma_text\n",
    "\n",
    "def compute_overlap(ocr_set, ar):\n",
    "    intersection = 0\n",
    "    if len(ar) == 0:\n",
    "        return 0\n",
    "    for el in ar:\n",
    "        if el in ocr_set:\n",
    "            intersection += 1\n",
    "    \n",
    "    return intersection/len(ar)\n",
    "\n",
    "def compute_scores(dataframe, ar_dict):\n",
    "    scores = []\n",
    "    for i in range(len(dataframe)):\n",
    "        im = dataframe.image_file[i]\n",
    "        ocr_set = set(preprocess_text(dataframe.text[i]))\n",
    "        for ar in ar_dict[im]:\n",
    "            scores.append(compute_overlap(ocr_set, preprocess_text(ar)))\n",
    "    \n",
    "    return np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21112030031086035\n",
      "0.02799327879886783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=295.64930142873544, pvalue=0.0, df=184558.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_right = compute_scores(ocr_df, right_dict)\n",
    "scores_wrong = compute_scores(ocr_df, wrong_dict)\n",
    "print(scores_right.mean())\n",
    "print(scores_wrong.mean())\n",
    "ttest_ind(scores_right, scores_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_overlap_orig = scores_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.779806262659946\n",
      "12.658216666904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=444.2081415327576, pvalue=0.0, df=184558.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clip scores\n",
    "\n",
    "clip_outs_right = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_test_right.pkl'), \"rb\"))\n",
    "clip_outs_wrong = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_test_wrong.pkl'), \"rb\"))\n",
    "\n",
    "def get_clip_scores(dataframe, clip_outputs):\n",
    "    im_paths = dataframe.image_file.values.tolist()\n",
    "    clip_sim = np.array([])\n",
    "    for path in im_paths:\n",
    "        logits = clip_outputs.out_dict[path]['logits']\n",
    "        clip_sim = np.concatenate((clip_sim, logits), axis=0)\n",
    "    \n",
    "    return clip_sim\n",
    "\n",
    "clip_scores_right = get_clip_scores(ocr_df, clip_outs_right)\n",
    "clip_scores_wrong = get_clip_scores(ocr_df, clip_outs_wrong)\n",
    "\n",
    "print(clip_scores_right.mean())\n",
    "print(clip_scores_wrong.mean())\n",
    "ttest_ind(clip_scores_right, clip_scores_wrong)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Overall correlation: SignificanceResult(statistic=0.45245768573873035, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Overall correlation:', spearmanr(np.concatenate((scores_wrong, scores_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence-level similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12085, 768)\n",
      "(37548, 768)\n",
      "(38734, 768)\n"
     ]
    }
   ],
   "source": [
    "ocr_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_ocr_text.pkl'), \"rb\"))\n",
    "right_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_corr_ar.pkl'), \"rb\"))\n",
    "wrong_outs = pickle.load(open(join(OUTPUT_PATH,'mpnet', 'all-mpnet-base-v2_wrong_ar.pkl'), \"rb\"))\n",
    "\n",
    "print(ocr_outs.embeddings.shape)\n",
    "print(wrong_outs.embeddings.shape)\n",
    "print(right_outs.embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim(ocr_t, image_path, ar_dict, ocr_outputs, ar_outputs):\n",
    "    ar_list = ar_dict[image_path]\n",
    "    n = len(ar_list)\n",
    "    # print(n)\n",
    "    res = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        res[i] = pearsonr(ocr_outputs(ocr_t), ar_outputs(ar_list[i]))[0]\n",
    "    \n",
    "    # print(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_sim_scores(dataframe, ar_dict, ocr_outputs, ar_outputs):\n",
    "    sim_scores = np.zeros(0)\n",
    "    for i in range(len(dataframe)):\n",
    "        text = dataframe.text[i]\n",
    "        path = dataframe.image_file[i]\n",
    "        sim = compute_sim(ocr_t=text, image_path=path, ar_dict=ar_dict, ocr_outputs=ocr_outputs, ar_outputs=ar_outputs)\n",
    "        sim_scores = np.concatenate((sim_scores, sim), axis=0)\n",
    "\n",
    "    return sim_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4056594954126213\n",
      "0.1292979560786269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=343.60494711862356, pvalue=0.0, df=184558.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_right = get_sim_scores(ocr_df, right_dict, ocr_outs, right_outs)\n",
    "scores_wrong = get_sim_scores(ocr_df, wrong_dict, ocr_outs, wrong_outs)\n",
    "print(scores_right.mean())\n",
    "print(scores_wrong.mean())\n",
    "ttest_ind(scores_right, scores_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sim_orig = scores_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Overall correlation: SignificanceResult(statistic=0.6109834865289566, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Overall correlation:', spearmanr(np.concatenate((scores_wrong, scores_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 8)\n",
      "Index(['index', 'image_path', 'distractor_1', 'distractor_2', 'flag', 'ar',\n",
      "       'annotator_id', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "df = pd.read_csv(join(OUTPUT_PATH, 'dist_w_ocr.csv'))\n",
    "df = df[~df.text.isnull()].reset_index()\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLIP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 8)\n",
      "24.86613\n",
      "24.420742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=1.2235935691912778, pvalue=0.22143311080394262, df=880.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "clip_our_dataset = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_our_dataset.pkl'), \"rb\"))\n",
    "clip_scores_right = np.array([clip_our_dataset.out_dict[df.image_path[i]]['logits'][0] for i in range(len(df))])\n",
    "clip_scores_wrong = np.array([clip_our_dataset.out_dict[df.image_path[i]]['logits'][1:] for i in range(len(df))]).flatten()\n",
    "print(clip_scores_right.mean())\n",
    "print(clip_scores_wrong.mean())\n",
    "ttest_ind(clip_scores_right, clip_scores_wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(lemmatizer, tokenizer, text):\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemma_text = [lemmatizer.lemmatize(t.lower()) for t in tokens if t not in stop_words]\n",
    "\n",
    "    return lemma_text\n",
    "\n",
    "def compute_overlap(ocr_set, ar):\n",
    "    intersection = 0\n",
    "    for el in ar:\n",
    "        if el in ocr_set:\n",
    "            intersection += 1\n",
    "    \n",
    "    return intersection/len(ar)\n",
    "\n",
    "def compute_scores_right(dataframe):\n",
    "    scores = []\n",
    "    for i in range(len(dataframe)):\n",
    "        \n",
    "        ocr_set = set(preprocess_text(lemmatizer, tokenizer, dataframe.text[i]))\n",
    "        scores.append(compute_overlap(ocr_set, preprocess_text(lemmatizer, tokenizer, dataframe.ar[i])))\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "def compute_scores_wrong(dataframe):\n",
    "    scores = []\n",
    "    for i in range(len(dataframe)):\n",
    "        \n",
    "        ocr_set = set(preprocess_text(lemmatizer, tokenizer, dataframe.text[i]))\n",
    "        scores.append(compute_overlap(ocr_set, preprocess_text(lemmatizer, tokenizer, dataframe.distractor_1[i])))\n",
    "        scores.append(compute_overlap(ocr_set, preprocess_text(lemmatizer, tokenizer, dataframe.distractor_2[i])))\n",
    "    \n",
    "    return np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2706212686744373 (294,)\n",
      "0.3139828331154862 (588,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.835571609692304, pvalue=0.0046792512242782944, df=880.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_right = compute_scores_right(df)\n",
    "scores_wrong = compute_scores_wrong(df)\n",
    "print(scores_right.mean(), scores_right.shape)\n",
    "print(scores_wrong.mean(), scores_wrong.shape)\n",
    "ttest_ind(scores_right, scores_wrong, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_overl_trade = scores_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Overall correlation: SignificanceResult(statistic=0.2655390641506729, pvalue=1.0632978378600645e-15)\n"
     ]
    }
   ],
   "source": [
    "print('Overall correlation:', spearmanr(np.concatenate((scores_wrong, scores_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic similarity with sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(join(OUTPUT_PATH, 'dist_w_ocr.csv'))\n",
    "df = df[~df.text.isnull()].reset_index()\n",
    "print(df.shape)\n",
    "ocr_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_ocr_text_our_distractors.pkl'), \"rb\"))\n",
    "right_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_corr_ar_our_distractors.pkl'), \"rb\"))\n",
    "wrong_outs = pickle.load(open(join(OUTPUT_PATH,'mpnet', 'all-mpnet-base-v2_wrong_ar_our_distractors.pkl'), \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44220495456887843\n",
      "0.42110715510001195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=1.7155641215005741, pvalue=0.08659384747839889, df=880.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_sim(dataframe, ocr_outputs, wrong_outputs):\n",
    "    ret = np.array([])\n",
    "    for i in range(len(dataframe)):\n",
    "        new_arr = np.zeros(2)\n",
    "        new_arr[0] = pearsonr(wrong_outputs(dataframe.distractor_1[i]), ocr_outputs(dataframe.text[i]))[0]\n",
    "        new_arr[1] = pearsonr(wrong_outputs(dataframe.distractor_2[i]), ocr_outputs(dataframe.text[i]))[0]\n",
    "        ret = np.concatenate((ret, new_arr))\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "scores_right = df.apply(lambda x: pearsonr(ocr_outs(x.text), right_outs(x.ar))[0], axis=1)\n",
    "scores_wrong = compute_sim(df, ocr_outs, wrong_outs)\n",
    "print(scores_right.mean())\n",
    "print(scores_wrong.mean())\n",
    "ttest_ind(scores_right, scores_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sim_trade = scores_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Overall correlation: SignificanceResult(statistic=0.40992078846339486, pvalue=4.578079555696565e-37)\n"
     ]
    }
   ],
   "source": [
    "print('Overall correlation:', spearmanr(np.concatenate((scores_wrong, scores_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-based grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12805\n",
      "Images were detected for 11351 objects\n",
      "An average of 3.74 (3.85) objects was detected per image\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "with open(join(OUTPUT_PATH,'test_right.json'), 'r') as my_right_file:\n",
    "    right_data=my_right_file.read()\n",
    "right_dict = json.loads(right_data)\n",
    "\n",
    "\n",
    "with open(join(OUTPUT_PATH,'test_wrong.json'), 'r') as my_wrong_file:\n",
    "    wrong_data=my_wrong_file.read()\n",
    "wrong_dict = json.loads(wrong_data)\n",
    "ocr_df = pd.read_csv(join(OUTPUT_PATH, 'text_sim.csv'))\n",
    "\n",
    "obj_outputs = pickle.load(open(join(OUTPUT_PATH, 'det2','short_mask_rcnn_R_50_FPN_3x.pkl'), \"rb\"))\n",
    "\n",
    "print(len(obj_outputs['objects']))\n",
    "\n",
    "l = []\n",
    "red_dict = {}\n",
    "for k in obj_outputs['objects']:\n",
    "    if len(obj_outputs['objects'][k]) > 0:\n",
    "        red_dict[k] = obj_outputs['objects'][k]\n",
    "        l.append(len(obj_outputs['objects'][k]))\n",
    "print(f'Images were detected for {len(red_dict)} objects')\n",
    "print(f'An average of {np.round(np.array(l).mean(),2)} ({np.round(np.array(l).std(),2)}) objects was detected per image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['JJ', 'NN', 'NNS', 'RB'], dtype='<U3')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = obj_outputs['classes']\n",
    "cl_arr = np.array([nltk.pos_tag([t])[0][1] for t in classes])\n",
    "np.unique(cl_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35617\n",
      "35617\n",
      "134648\n",
      "134648\n"
     ]
    }
   ],
   "source": [
    "def clean_text(sentence):\n",
    "\ttokenizer = RegexpTokenizer(r'\\w+')\n",
    "\tlemmatizer = WordNetLemmatizer()\n",
    "\tpos_tags = nltk.pos_tag(tokenizer.tokenize(sentence))\n",
    "\tret_s = [lemmatizer.lemmatize(el[0].lower()) for el in pos_tags if el[1] in ['NN', 'NNP', 'NNS']]\n",
    "\t\t\n",
    "\treturn ret_s\n",
    "\n",
    "def get_classes_list(class_names, class_numbers):\n",
    "    ret = [class_names[i] for i in class_numbers]\n",
    "    return ret\n",
    "\n",
    "\n",
    "classes = obj_outputs['classes']\n",
    "right_ar = []\n",
    "right_obj = []\n",
    "wrong_ar = []\n",
    "wrong_obj = []\n",
    "for k in red_dict:\n",
    "    for ar in right_dict[k]:\n",
    "        right_ar.append(clean_text(ar))\n",
    "        right_obj.append(get_classes_list(classes, red_dict[k]))\n",
    "    for ar in wrong_dict[k]:\n",
    "        wrong_ar.append(clean_text(ar))\n",
    "        wrong_obj.append(get_classes_list(classes, red_dict[k]))\n",
    "\n",
    "print(len(right_ar))\n",
    "print(len(right_obj))\n",
    "print(len(wrong_ar))\n",
    "print(len(wrong_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35617\n",
      "35617\n",
      "134648\n",
      "134648\n"
     ]
    }
   ],
   "source": [
    "# original setup\n",
    "classes = obj_outputs['classes']\n",
    "right_ar = []\n",
    "right_obj = []\n",
    "wrong_ar = []\n",
    "wrong_obj = []\n",
    "for k in red_dict:\n",
    "    for ar in right_dict[k]:\n",
    "        right_ar.append(clean_text(ar))\n",
    "        right_obj.append(get_classes_list(classes, red_dict[k]))\n",
    "    for ar in wrong_dict[k]:\n",
    "        wrong_ar.append(clean_text(ar))\n",
    "        wrong_obj.append(get_classes_list(classes, red_dict[k]))\n",
    "\n",
    "print(len(right_ar))\n",
    "print(len(right_obj))\n",
    "print(len(wrong_ar))\n",
    "print(len(wrong_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027336710966017193\n",
      "0.008844132064306147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=36.09690184426529, pvalue=3.041267010948811e-284, df=170263.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_overlap(obj_set, ar_list):\n",
    "    \n",
    "    if len(ar_list) == 0:\n",
    "        return 0\n",
    "    intersection = 0\n",
    "    for el in ar_list:\n",
    "        if el in obj_set:\n",
    "            intersection += 1\n",
    "    \n",
    "    return intersection/len(ar_list)\n",
    "\n",
    "overl_right = np.array([compute_overlap(set(right_obj[i]), right_ar[i] ) for i in range(len(right_ar))])\n",
    "overl_wrong = np.array([compute_overlap(set( wrong_obj[i]), wrong_ar[i]) for i in range(len(wrong_ar))])\n",
    "print(overl_right.mean())\n",
    "print(overl_wrong.mean())\n",
    "ttest_ind(overl_right, overl_wrong)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.720198524166612\n",
      "12.737644326339097\n",
      "TtestResult(statistic=422.74555826261627, pvalue=0.0, df=170263.0)\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Overall correlation: SignificanceResult(statistic=0.1377801591338042, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "def get_clip_scores(ar_dict, clip_outputs):\n",
    "    im_paths = list(ar_dict.keys())\n",
    "    clip_sim = np.array([])\n",
    "    for path in im_paths:\n",
    "        logits = clip_outputs.out_dict[path]['logits']\n",
    "        clip_sim = np.concatenate((clip_sim, logits), axis=0)\n",
    "    \n",
    "    return clip_sim\n",
    "        \n",
    "red_right_dict = {k: right_dict[k] for k in right_dict if k in red_dict}\n",
    "red_wrong_dict = {k: wrong_dict[k] for k in wrong_dict if k in red_dict}\n",
    "clip_outs_right = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_test_right.pkl'), \"rb\"))\n",
    "clip_outs_wrong = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_test_wrong.pkl'), \"rb\"))\n",
    "clip_scores_right = get_clip_scores(red_right_dict, clip_outs_right)\n",
    "clip_scores_wrong = get_clip_scores(red_wrong_dict, clip_outs_wrong)\n",
    "print(clip_scores_right.mean())\n",
    "print(clip_scores_wrong.mean())\n",
    "print(ttest_ind(clip_scores_right, clip_scores_wrong))\n",
    "\n",
    "print('Overall correlation:', spearmanr(np.concatenate((overl_wrong, overl_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_mention_orig = overl_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join(OUTPUT_PATH, 'text_sim.csv'))\n",
    "captions = pickle.load(open(join(OUTPUT_PATH, 'blip2', 'blip2-opt-2.7b_blip_captions_wrong.pkl'), \"rb\"))\n",
    "capt_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_caption_embeddings.pkl'), \"rb\"))\n",
    "right_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_corr_ar.pkl'), \"rb\"))\n",
    "wrong_outs = pickle.load(open(join(OUTPUT_PATH,'mpnet', 'all-mpnet-base-v2_wrong_ar.pkl'), \"rb\"))\n",
    "clip_outs_right = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_test_right.pkl'), \"rb\"))\n",
    "clip_outs_wrong = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_test_wrong.pkl'), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim(cap_t, image_path, ar_dict, cap_outputs, ar_outputs):\n",
    "    ar_list = ar_dict[image_path]\n",
    "    n = len(ar_list)\n",
    "    # print(n)\n",
    "    res = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        res[i] = pearsonr(cap_outputs(cap_t), ar_outputs(ar_list[i]))[0]\n",
    "    \n",
    "    # print(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_sim_scores(key_list, captions, ar_dict, cap_outputs, ar_outputs):\n",
    "    sim_scores = np.zeros(0)\n",
    "    for i in range(len(key_list)):\n",
    "     \n",
    "        path = key_list[i]\n",
    "        text = captions['outputs'][path]['caption']\n",
    "        sim = compute_sim(cap_t=text, image_path=path, ar_dict=ar_dict, cap_outputs=cap_outputs, ar_outputs=ar_outputs)\n",
    "        sim_scores = np.concatenate((sim_scores, sim), axis=0)\n",
    "\n",
    "    return sim_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3159710148179032\n",
      "0.10862949894945366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=276.47171918205925, pvalue=0.0, df=192073.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_right = get_sim_scores(list(right_dict.keys()), captions, right_dict, capt_outs, right_outs)\n",
    "scores_wrong = get_sim_scores(list(right_dict.keys()), captions, wrong_dict, capt_outs, wrong_outs)\n",
    "print(scores_right.mean())\n",
    "print(scores_wrong.mean())\n",
    "ttest_ind(scores_right, scores_wrong)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_sim_orig = scores_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.72006608930263\n",
      "12.680320747900193\n",
      "TtestResult(statistic=450.6241275160643, pvalue=0.0, df=192073.0)\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Overall correlation: SignificanceResult(statistic=0.5276868498200121, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "def get_clip_scores(key_list, clip_outputs):\n",
    "    clip_sim = np.array([])\n",
    "    for path in key_list:\n",
    "        logits = clip_outputs.out_dict[path]['logits']\n",
    "        clip_sim = np.concatenate((clip_sim, logits), axis=0)\n",
    "    \n",
    "    return clip_sim\n",
    "\n",
    "clip_scores_right = get_clip_scores(list(right_dict.keys()), clip_outs_right)\n",
    "clip_scores_wrong = get_clip_scores(list(wrong_dict.keys()), clip_outs_wrong)\n",
    "\n",
    "print(clip_scores_right.mean())\n",
    "print(clip_scores_wrong.mean())\n",
    "print(ttest_ind(clip_scores_right, clip_scores_wrong))\n",
    "\n",
    "print('Overall correlation:', spearmanr(np.concatenate((scores_wrong, scores_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLIP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 7)\n",
      "24.842833\n",
      "24.385693\n",
      "TtestResult(statistic=1.2651321675697134, pvalue=0.20615213969344062, df=898.0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(join(OUTPUT_PATH, 'dist_w_ocr.csv'))\n",
    "print(df.shape)\n",
    "clip_our_dataset = pickle.load(open(join(OUTPUT_PATH, 'clip','clip-vit-large-patch14-336_clip_score_our_dataset.pkl'), \"rb\"))\n",
    "clip_scores_right = np.array([clip_our_dataset.out_dict[df.image_path[i]]['logits'][0] for i in range(len(df))])\n",
    "clip_scores_wrong = np.array([clip_our_dataset.out_dict[df.image_path[i]]['logits'][1:] for i in range(len(df))]).flatten()\n",
    "print(clip_scores_right.mean())\n",
    "print(clip_scores_wrong.mean())\n",
    "print(ttest_ind(clip_scores_right, clip_scores_wrong))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemma overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Images were detected for 300 objects\n",
      "An average of 3.51 (3.38) objects was detected per image\n"
     ]
    }
   ],
   "source": [
    "# our dataset\n",
    "obj_outputs = pickle.load(open(join(OUTPUT_PATH, 'det2','ours_slurm_mask_rcnn_R_50_FPN_3x.pkl'), \"rb\"))\n",
    "\n",
    "print(len(obj_outputs))\n",
    "\n",
    "l = []\n",
    "red_dict = {}\n",
    "for k in obj_outputs:\n",
    "    if len(obj_outputs[k]) > 0:\n",
    "        red_dict[k] = obj_outputs[k]['pred_classes']\n",
    "        l.append(len(obj_outputs[k]['pred_classes']))\n",
    "print(f'Images were detected for {len(red_dict)} objects')\n",
    "print(f'An average of {np.round(np.array(l).mean(),2)} ({np.round(np.array(l).std(),2)}) objects was detected per image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022809523809523807 (300,)\n",
      "0.03536574074074073 (600,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.4576480091118431, pvalue=0.14528719856443884, df=898.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(sentence):\n",
    "\ttokenizer = RegexpTokenizer(r'\\w+')\n",
    "\tlemmatizer = WordNetLemmatizer()\n",
    "\tpos_tags = nltk.pos_tag(tokenizer.tokenize(sentence))\n",
    "\tret_s = [lemmatizer.lemmatize(el[0].lower()) for el in pos_tags if el[1] in ['NN', 'NNP', 'NNS']]\n",
    "\t\t\n",
    "\treturn ret_s\n",
    "\n",
    "def compute_overlap(obj_set, ar_list):\n",
    "    \n",
    "    if len(ar_list) == 0:\n",
    "        return 0\n",
    "    intersection = 0\n",
    "    for el in ar_list:\n",
    "        if el in obj_set:\n",
    "            intersection += 1\n",
    "    \n",
    "    return intersection/len(ar_list)\n",
    "\n",
    "right_ar = []\n",
    "right_obj = []\n",
    "wrong_ar = []\n",
    "wrong_obj = []\n",
    "for i in range(len(df)):\n",
    "    im = df.image_path[i]\n",
    "    right_ar.append(clean_text(df.ar[i]))\n",
    "    right_obj.append(get_classes_list(classes, red_dict[im]))\n",
    "    wrong_ar.append(clean_text(df.distractor_1[i]))\n",
    "    wrong_ar.append(clean_text(df.distractor_2[i]))\n",
    "    wrong_obj.append(get_classes_list(classes, red_dict[im]))\n",
    "    wrong_obj.append(get_classes_list(classes, red_dict[im]))\n",
    "\n",
    "\n",
    "overl_right = np.array([compute_overlap(set(right_obj[i]), right_ar[i] ) for i in range(len(right_ar))])\n",
    "overl_wrong = np.array([compute_overlap(set( wrong_obj[i]), wrong_ar[i]) for i in range(len(wrong_ar))])\n",
    "print(overl_right.mean(), overl_right.shape)\n",
    "print(overl_wrong.mean(), overl_wrong.shape)\n",
    "ttest_ind(overl_right, overl_wrong)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_mention_trade = overl_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "SignificanceResult(statistic=0.04066508794897715, pvalue=0.22293479751555514)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(np.concatenate((overl_wrong, overl_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_corr_ar_our_distractors.pkl'), \"rb\"))\n",
    "wrong_outs = pickle.load(open(join(OUTPUT_PATH,'mpnet', 'all-mpnet-base-v2_wrong_ar_our_distractors.pkl'), \"rb\"))\n",
    "captions = pickle.load(open(join(OUTPUT_PATH, 'blip2', 'blip2-opt-2.7b_blip_captions.pkl'), \"rb\"))\n",
    "capt_outs = pickle.load(open(join(OUTPUT_PATH, 'mpnet', 'all-mpnet-base-v2_caption_embeddings_ours.pkl'), \"rb\"))\n",
    "df = pd.read_csv(join(OUTPUT_PATH, 'dist_w_ocr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34228443398276237 (300,)\n",
      "0.346720127807326 (300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-0.36493185801230943, pvalue=0.7152481990220099, df=898.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_sim(dataframe, captions, capt_outputs, wrong_outputs):\n",
    "    ret = np.array([])\n",
    "    for i in range(len(dataframe)):\n",
    "        new_arr = np.zeros(2)\n",
    "    \n",
    "        new_arr[0] = pearsonr(wrong_outputs(dataframe.distractor_1[i]), capt_outputs(captions['outputs'][dataframe.image_path[i]]['caption']))[0]\n",
    "        new_arr[1] = pearsonr(wrong_outputs(dataframe.distractor_2[i]), capt_outputs(captions['outputs'][dataframe.image_path[i]]['caption']))[0]\n",
    "        ret = np.concatenate((ret, new_arr))\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "scores_right = df.apply(lambda x: pearsonr(capt_outs(captions['outputs'][x.image_path]['caption']), right_outs(x.ar))[0], axis=1)\n",
    "scores_wrong = compute_sim(df,captions, capt_outs, wrong_outs)\n",
    "print(scores_right.mean(), scores_right.shape)\n",
    "print(scores_wrong.mean(), scores_right.shape)\n",
    "ttest_ind(scores_right, scores_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_sim_trade = scores_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "SignificanceResult(statistic=0.29854899409340835, pvalue=5.507669434536161e-20)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(np.concatenate((scores_wrong, scores_right), axis=0), \n",
    "                                           np.concatenate((clip_scores_wrong, clip_scores_right)), \n",
    "                                           alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38596,)\n",
      "(294,)\n",
      "(38596,)\n",
      "(294,)\n",
      "(35617,)\n",
      "(300,)\n",
      "(40171,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(text_overlap_orig.shape)\n",
    "print(text_overl_trade.shape)\n",
    "print(text_sim_orig.shape)\n",
    "print(text_sim_trade.shape)\n",
    "print(obj_mention_orig.shape)\n",
    "print(obj_mention_trade.shape)\n",
    "print(cap_sim_orig.shape)\n",
    "print(cap_sim_trade.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21112030031086035\n",
      "0.2706212686744373\n",
      "0.4056594954126213\n",
      "0.44220495456887843\n",
      "0.027336710966017193\n",
      "0.022809523809523807\n",
      "0.3159710148179032\n",
      "0.34228443398276237\n"
     ]
    }
   ],
   "source": [
    "print(text_overlap_orig.mean())\n",
    "print(text_overl_trade.mean())\n",
    "print(text_sim_orig.mean())\n",
    "print(text_sim_trade.mean())\n",
    "print(obj_mention_orig.mean())\n",
    "print(obj_mention_trade.mean())\n",
    "print(cap_sim_orig.mean())\n",
    "print(cap_sim_trade.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({'text_overlap_orig': text_overlap_orig,\n",
    "         'text_overlap_trade': text_overl_trade,\n",
    "         'text_sim_orig': text_sim_orig,\n",
    "         'text_sim_trade': text_sim_trade,\n",
    "         'obj_mention_origin': obj_mention_orig,\n",
    "         'obj_mention_trade': obj_mention_trade,\n",
    "         'cap_sim_origin': cap_sim_orig,\n",
    "         'cap_sim_trade': cap_sim_trade}, open('grounding_scores.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
